# -*- coding: utf-8 -*-
"""ML_HW4

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10vp63Lpe2XHFnAySIWq95ioIJYFfGKjx

# **ML4 - Linear Regression & Logistic Regression**

學號：0812203

姓名：蔡銘萱
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.metrics import classification_report

"""# Linear Regression

## Data Generation
"""

def linear_data(seed = 0):
  np.random.seed(seed)
  mean, std = 0, 0.5
  eps = np.random.normal(mean, std, 1000)
  x = np.random.uniform(-1.5, 1.0, 1000)
  y = 3*x*x*x + 2*x*x - 3*x + 1 + eps
  data = np.column_stack((x, y))
  x = x[:, np.newaxis]
  y = y[:, np.newaxis]
  return x, y

x, y = linear_data()

plt.figure(figsize=(12,6))
plt.scatter(x, y, color="orange", alpha=0.3)
plt.show()

"""## Data Preprocessing"""

def linear_process(x, degree):
  poly = PolynomialFeatures(degree = degree)
  trans_x = poly.fit_transform(x)
  return trans_x

trans_X1 = linear_process(x, 1)
trans_X2 = linear_process(x, 2)
trans_X3 = linear_process(x, 3)
trans_X4 = linear_process(x, 4)

"""## Model Construction"""

def linear_regression(x, y):
  model = LinearRegression()
  model.fit(x, y)
  y_pred = model.predict(x)
  return model

model_1 = linear_regression(trans_X1, y)
model_2 = linear_regression(trans_X2, y)
model_3 = linear_regression(trans_X3, y)
model_4 = linear_regression(trans_X4, y)

"""## Result"""

def get_test_y(x, degree):
  if degree == 1:
    return model_1.intercept_[0] + model_1.coef_[0, 1]*x
  elif degree == 2:
    return model_2.intercept_[0] + model_2.coef_[0, 1]*x + model_2.coef_[0, 2]*x**2
  elif degree == 3:
    return model_3.intercept_[0] + model_3.coef_[0, 1]*x + model_3.coef_[0, 2]*x**2 + model_3.coef_[0, 3]*x**3
  elif degree == 4:
    return model_4.intercept_[0] + model_4.coef_[0, 1]*x + model_4.coef_[0, 2]*x**2 + model_4.coef_[0, 3]*x**3 + model_4.coef_[0, 4]*x**4

test_x = np.arange(-1.5, 1, 0.01)
test_y1 = get_test_y(test_x, 1)
test_y2 = get_test_y(test_x, 2)
test_y3 = get_test_y(test_x, 3)
test_y4 = get_test_y(test_x, 4)

def get_poly(model):
  coef = model.coef_[0]
  coef[0] = model.intercept_[0]
  poly=""
  for i in range(len(coef)):
    if(round(coef[i],2) > 0 and i > 0):
      poly = poly + '+'
    poly = poly + str(round(coef[i],2))
    if(i == 1):
      poly = poly + '$$\\times$$' + 'x_i'
    elif(i > 1):
      poly = poly + '$$\\times$$' + 'x^' + str(i) + '_i'
  return '$' + poly + '$'

plt.figure(figsize=(12,6))
plt.xlabel('x')
plt.ylabel('y')
plt.scatter(x, y, color="orange", alpha=0.3)
plt.plot(test_x, test_y1, color = "skyblue", linewidth = 1, label = get_poly(model_1))
plt.plot(test_x, test_y2, color = "orangered", linewidth = 1, label = get_poly(model_2))
plt.plot(test_x, test_y3, color = "green", linewidth = 1, label = get_poly(model_3))
plt.plot(test_x, test_y4, color = "red", linewidth = 1, label = get_poly(model_4))
plt.legend()
plt.show()

"""# Logistic Regression

## Data Generation
"""

# https://blog.csdn.net/zch1990s/article/details/80005940

def logistic_data(seed = 0):
  
  np.random.seed(seed)
  n = np.random.binomial(1000, 0.5, 1)
  #print(n)
  con = [[0.1, 0], [0, 0.1]]

  y0 = np.zeros(n)
  x0 = np.random.multivariate_normal([0, 0], con, n)
  y1 = np.ones(1000 - n)
  x1 = np.random.multivariate_normal([1, 1], con, 1000 - n)
  #print(x0)
  #print(x1)

  X = np.concatenate([x0, x1])
  Y = np.concatenate([y0, y1])

  return X, Y, x0, y0, x1, y1

X, Y, x0, y0, x1, y1 = logistic_data()

plt.figure(figsize = (6, 6))
plt.xlabel('$x_{i0}$')
plt.ylabel('$x_{i1}$')
plt.scatter(x0[:, 0], x0[:, 1], color = 'steelblue', label = '$y_i=0$')
plt.scatter(x1[:, 0], x1[:, 1], color = 'darkorange', label = '$y_i=1$')
plt.legend()
plt.show()

"""## Model Construction"""

def logistic_regression(x, y):
  model = LogisticRegression()
  model.fit(x, y)
  y_pred = model.predict(x)
  print("Report: \n", classification_report(y, y_pred))
  return model

model = logistic_regression(X, Y)

"""## Results"""

# https://ithelp.ithome.com.tw/articles/10203937

plt.figure(figsize=(6, 6))
plt.xlabel('$x_{i0}$')
plt.ylabel('$x_{i1}$')

x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1
y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1
xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),np.arange(y_min, y_max, 0.02))
Z = model.predict(np.array([xx.ravel(), yy.ravel()]).T)
Z = Z.reshape(xx.shape)
plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Pastel1)

plt.scatter(x0[:, 0], x0[:, 1], color = 'steelblue', edgecolor='black', label = '$y_i=0$')
plt.scatter(x1[:, 0], x1[:, 1], color = 'darkorange', edgecolor='black', label = '$y_i=1$')

L = '$y_i=L(' + str(round(model.intercept_[0], 1)) + '+' + str(round(model.coef_[0, 0], 1)) + '$$\\times$$x_{i0}+' + str(round(model.coef_[0, 1], 1)) + '$$\\times$$x_{i1})$'
plt.title(L)

plt.legend()
plt.show()